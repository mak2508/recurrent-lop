{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models import MLP, LSTM\n",
    "from train import train_model\n",
    "from utils import shuffle_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Load and preprocess MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                         train=True,\n",
    "                                         transform=transform,\n",
    "                                         download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
    "                                        train=False, \n",
    "                                        transform=transform)\n",
    "\n",
    "# Create shuffled data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                         batch_size=128,\n",
    "                         shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                        batch_size=128,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "input_size = 28 * 28  # MNIST images are 28x28\n",
    "hidden_size = 25\n",
    "num_classes = 10\n",
    "num_epochs = 50\n",
    "batch_size = 6000 #None # 128\n",
    "learning_rate = 0.01\n",
    "dropout_rate = 0.0\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLP(\n",
    "    input_size=input_size, \n",
    "    hidden_size=hidden_size, \n",
    "    num_classes=num_classes, \n",
    "    dropout_rate=dropout_rate\n",
    ").to(device)\n",
    "mlp_model_criterion = nn.CrossEntropyLoss()\n",
    "mlp_model_optimizer = torch.optim.Adam(mlp_model.parameters(), lr=learning_rate)\n",
    "\n",
    "lstm_model = LSTM(\n",
    "    input_size=28, # each sequence has 28 features\n",
    "    hidden_size=hidden_size, \n",
    "    num_layers=1, \n",
    "    num_classes=num_classes, \n",
    "    dropout_rate=dropout_rate\n",
    ").to(device)\n",
    "lstm_model_criterion = nn.CrossEntropyLoss()\n",
    "lstm_model_optimizer = torch.optim.Adam(lstm_model.parameters(), lr=learning_rate)\n",
    "\n",
    "models = []\n",
    "\n",
    "models.append(('mlp', mlp_model, mlp_model_criterion, mlp_model_optimizer))\n",
    "models.append(('lstm', lstm_model, lstm_model_criterion, lstm_model_optimizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_shuffles=30\n",
    "train_logs = {}\n",
    "\n",
    "for model_name, model, criterion, optimizer in models:\n",
    "    # Initialize lists to store results for all runs\n",
    "    all_train_losses = []\n",
    "    all_test_accuracies = []\n",
    "    all_label_mappings = []\n",
    "    \n",
    "\n",
    "    # Repeat training with different label shufflings\n",
    "    for run in range(num_shuffles):\n",
    "        print(f\"\\nStarting Run {run + 1}/{num_shuffles}\")\n",
    "        \n",
    "        # Shuffle the labels\n",
    "        shuffled_train, label_mapping = shuffle_labels(train_dataset)\n",
    "        shuffled_test, _ = shuffle_labels(test_dataset, label_mapping)  # Use same mapping for test set\n",
    "        \n",
    "        # Print the label mapping for this run\n",
    "        print(\"Label mapping for this run:\")\n",
    "        print(\"Original:  \", \" \".join(str(i) for i in range(10)))\n",
    "        print(\"Mapped to: \", \" \".join(str(label_mapping[i]) for i in range(10)))\n",
    "        \n",
    "        # Train the model\n",
    "        train_losses, test_accuracies = train_model(\n",
    "            model=model, \n",
    "            train_data=shuffled_train, \n",
    "            test_data=shuffled_test, \n",
    "            num_epochs=num_epochs, \n",
    "            device=device, \n",
    "            criterion=criterion, \n",
    "            optimizer=optimizer,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "        \n",
    "        # Store results\n",
    "        all_train_losses.append(train_losses)\n",
    "        all_test_accuracies.append(test_accuracies)\n",
    "        all_label_mappings.append(label_mapping)\n",
    "    \n",
    "    train_logs[model_name] = {\n",
    "        'all_train_losses': all_train_losses,\n",
    "        'all_test_accuracies': all_test_accuracies,\n",
    "        'all_label_mappings': all_label_mappings\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, train_log in train_logs.items():\n",
    "    all_train_losses = train_log['all_train_losses']\n",
    "    all_test_accuracies = train_log['all_test_accuracies']\n",
    "    all_label_mappings = train_log['all_label_mappings']\n",
    "\n",
    "    # Create separate figures for loss and accuracy\n",
    "    # Loss figure\n",
    "    fig_loss = plt.figure(figsize=(15, 5))\n",
    "    combined_losses = [loss for run_losses in all_train_losses for loss in run_losses]\n",
    "    plt.plot(combined_losses)\n",
    "    plt.title('Training Loss', fontsize=14)\n",
    "    plt.xlabel('Training Steps', fontsize=12)\n",
    "    plt.ylabel('Loss', fontsize=12)\n",
    "    for i in range(1, num_shuffles):\n",
    "        plt.axvline(x=i*len(combined_losses)//num_shuffles, color='red', linestyle='--', alpha=0.5)\n",
    "    plt.savefig(f'mnist_reshuffle_{model_name}_loss.png')\n",
    "    plt.close(fig_loss)\n",
    "\n",
    "    # Accuracy figure\n",
    "    fig_acc = plt.figure(figsize=(15, 5))\n",
    "    combined_accuracies = [acc for run_accuracies in all_test_accuracies for acc in run_accuracies]\n",
    "    plt.plot(combined_accuracies)\n",
    "    plt.title('Test Accuracy', fontsize=14)\n",
    "    plt.xlabel('Epochs', fontsize=12)\n",
    "    plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "    for i in range(1, num_shuffles):\n",
    "        plt.axvline(x=i*len(combined_accuracies)//num_shuffles, color='red', linestyle='--', alpha=0.5)\n",
    "    plt.savefig(f'mnist_reshuffle_{model_name}_accuracy.png')\n",
    "    plt.close(fig_acc)\n",
    "\n",
    "    # If you also want to display them together\n",
    "    fig_combined, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))\n",
    "    \n",
    "    ax1.plot(combined_losses)\n",
    "    ax1.set_title('Training Loss', fontsize=14)\n",
    "    ax1.set_xlabel('Training Steps', fontsize=12)\n",
    "    ax1.set_ylabel('Loss', fontsize=12)\n",
    "    for i in range(1, num_shuffles):\n",
    "        ax1.axvline(x=i*len(combined_losses)//num_shuffles, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "    ax2.plot(combined_accuracies)\n",
    "    ax2.set_title('Test Accuracy', fontsize=14)\n",
    "    ax2.set_xlabel('Epochs', fontsize=12)\n",
    "    ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    for i in range(1, num_shuffles):\n",
    "        ax2.axvline(x=i*len(combined_accuracies)//num_shuffles, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'mnist_reshuffle_{model_name}_combined.png')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
